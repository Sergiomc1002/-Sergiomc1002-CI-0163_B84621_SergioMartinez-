{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953 (0.048)\n"
     ]
    }
   ],
   "source": [
    "# baseline model performance on the wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968 (0.037)\n"
     ]
    }
   ],
   "source": [
    "# data preparation as feature engineering for wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# transforms for the feature union\n",
    "transforms = list()\n",
    "transforms.append(('mms', MinMaxScaler()))\n",
    "transforms.append(('ss', StandardScaler()))\n",
    "transforms.append(('rs', RobustScaler()))\n",
    "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "transforms.append(('pca', PCA(n_components=7)))\n",
    "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "# create the feature union\n",
    "fu = FeatureUnion(transforms)\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('fu', fu))\n",
    "steps.append(('m', model))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989 (0.022)\n"
     ]
    }
   ],
   "source": [
    "# data preparation as feature engineering with feature selection for wine dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
    "df = read_csv(url, header=None)\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# transforms for the feature union\n",
    "transforms = list()\n",
    "transforms.append(('mms', MinMaxScaler()))\n",
    "transforms.append(('ss', StandardScaler()))\n",
    "transforms.append(('rs', RobustScaler()))\n",
    "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "transforms.append(('pca', PCA(n_components=7)))\n",
    "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "# create the feature union\n",
    "fu = FeatureUnion(transforms)\n",
    "# define the feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=15)\n",
    "# define the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('fu', fu))\n",
    "steps.append(('rfe', rfe))\n",
    "steps.append(('m', model))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# define the cross-validation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fue bastante útil ver estos algoritmos aplicados, aunque me gustaría verlos de manera más gráfica, procedere a buscar diferentes ejemplos en el futuro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
